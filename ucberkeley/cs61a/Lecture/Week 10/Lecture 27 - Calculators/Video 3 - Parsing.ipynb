{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writer Note:\n",
    "This notebook involves both Scheme code and Python code and so, 2 different kernels are needed to read/execute the cells correctly. Since the beginning of the lecture uses Scheme code, the Calysto Scheme kernel will be used at first. However, at a certain point in the notes, you will be suggested to switch to Python kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing is the process of taking texts input (which represents a computer program or some other formal language expression) and turns those into some sort of object that represents the expressions while validating their syntax.\n",
    "\n",
    "A parser takes text and returns an expression. This happens through an intermediate called **Tokens**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'token.jpg' width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lexical analysis** is the process of breaking up texts into tokens (e.g. words or individual symbols). Then we do **Syntactic analysis** to figure out how these symbols nest into hierarchical expression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'syntactic.jpg' width = 600/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we typed the following 3 lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3999999999999986"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "( + 1\n",
    "  (- 23)\n",
    "  (* 4 5.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of Lexical analysis breaks up each line into the right pieces for input in the Syntactic analysis. \n",
    "\n",
    "<img src = '1.jpg' width = 700/>\n",
    "\n",
    "These are the pieces that represent whole numbers or special symbols such as parentheses `(` or symbols in the language such as `+`.\n",
    "\n",
    "As we can see, the line,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(+ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is broken up to 3 tokens: `(`, `+`, and `1`\n",
    "\n",
    "Meanwhile the line below,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  (- 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line is converted into 4 tokens: `(`, `-`, `23`, and `)`.\n",
    "\n",
    "Notice that the number `23` is treated as one token instead of separated to `2` and `3`. Lexical analysis figured out that `2` and `3` next to each other means the number `23`.\n",
    "\n",
    "Also notice that there are whitespace before the open parentheses `(`. Part of lexical analysis is to figure out what to discard. In this case, the whitespace is ignored.\n",
    "\n",
    "For the last line,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   (* 4 5.6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line is broken down to 6 tokens: `(`, `*`, `4`, `5.6`, `)`, `)`.\n",
    "\n",
    "See that the lexical analysis is able to tell that `5.6` is all in one token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'lexical.jpg' width = 500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Syntactic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactic analysis processes all the tokens to give us expressions in the language that we're trying to parse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactic analysis, in addition to skipping the whitespaces, figured out the structure of the expression, balanced out the parentheses and created the nested tree structure represented as `Pair` structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'syntactic1.jpg' width = 500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'whole.jpg' width = 700/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Syntactic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive syntactic analysis is a standard problem in CS brought up all the time. \n",
    "\n",
    "We're going to build a particular type of parser for the Scheme expressions that we want to parse, called **predictive recursive descent parser**. This parser inspect only `k` tokens to decide how to proceed (e.g. what sort of structure is going to be built). It does this for some fixed `k` (meaning: we don't need to look too far ahead to understand what's going on in the program).\n",
    "\n",
    "Let's try recursive descent parser on the English language. Can english be parsed via predictive recursive descent? To answer this question, let's analyze the following sentence:\n",
    "\n",
    "$$ \\text{The horse raced past the barn fell}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a well-formed sentence in English, but there are a few things that are unusual:\n",
    "\n",
    "1. Think of the word **raced** as a synonym for **ridden**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'ridden.jpg' width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The word **that was** has been ommitted from the sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'that.jpg' width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the word **The horse that was ridden past the barn** is a sentence subject. It was in the original version of the sentence, but this version is easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'sentence.jpg' width = 400/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason this is a hard sentence to read is that when we read **The horse raced past the barn**, we assumed a structural analysis:\n",
    "\n",
    "1. **raced** is the verb\n",
    "2. **The horse** is the subject\n",
    "3. **Past the barn** is a modifier of the verb telling us where the horse raced.\n",
    "    * However, it was not the horse that was racing\n",
    "    * Instead, someone was racing the horse\n",
    "    \n",
    "We had to look at the last word, **fell**, to resolve the the structural ambiguity. \n",
    "\n",
    "Thus, English is not something that can be parsed via recursive descent parser. Fortunately, Scheme expressions are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntactic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Syntactic analysis in Scheme expressions and other programming languages in general can use recursive descent parsers. It identifies the hierarchical structure of an expression, which may be nested.\n",
    "\n",
    "Each call to `scheme_read` consumes the input tokens for exactly one expression.\n",
    "\n",
    "1. The base case is that we only found symbols, or numbers.\n",
    "2. The recursive call: `scheme_read` sub-expressions and combine them\n",
    "    * Whenever we see an open parentheses `(`, we know that that's a combination with expressions within it\n",
    "    * Each one must be `scheme_read` itself. \n",
    "\n",
    "Thus, if we have a nested expression such as the following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'(', '+', 1, '(', '-', 23, ')', '(', '*', 4, 5.6, ')', ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'('"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the first call of `scheme_read`, it reads the `(`. It notices that we've started a combination, and therefore we'll have a sequence of subexpressions until we close that parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'+'\n",
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next 2 tokens are base cases: `+` and `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'(', '-', 23, ')' ; A sub expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next call to `scheme_read` is going to do a bunch of work. It's going to read the whole sub-expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'(', '*', 4, 5.6, ')' ; Another sub-expression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the next call will read the sub-expression as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "')'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it'll find the end of the expression that it started in the beginning. This is how `scheme_read` works. \n",
    "\n",
    "Let's go back to `scheme_read` and analyze it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writer Note: Switch to Python kernel\n",
    "\n",
    "Starting from this point, switch to Python kernel to be able to read the following codes correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `scheme_read`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheme_read(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes in `src`, which is some source tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if src.current() is None:\n",
    "    raise EOFError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, if we ran out of tokens, raise an **End of File Error**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = src.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ otherwise, get the first token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if val == 'nil':\n",
    "    return nil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ if it's a `nil`, that's a base case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif val not in DELIMITERS:  # ( ) ' .\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `val` not in `DELIMITERS`, meaning it's neither of the following:\n",
    "* `(`\n",
    "* `)`\n",
    "* `'`\n",
    "* `.`\n",
    "\n",
    "then just return that value. This is when we get numbers and symbols as a base case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif val == \"(\":\n",
    "    return read_tail(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ Otherwise, if we just opened up a combination with an open parentheses `(`, then we `return read_tail(src)`, which means we \"return the remainder of a list in src, starting before an element or closing parentheses `)`.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `read_tail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if src.current() is None:\n",
    "    raise SyntaxError(\"unexpected end of file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ if we run out of text before coming across any `)`, raise a `SyntaxError`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if src.current() == \")\":\n",
    "    src.pop()\n",
    "    return nil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ if we come across a `)`, then this is a base case, and we're done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = scheme_read(src)\n",
    "rest = read_tail(src)\n",
    "return Pair(first, rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "^ otherwise, we find the `first` and `rest`, and return a `Pair` containing the `first` and the `rest`.\n",
    "\n",
    "The `first` is a recursive call to `scheme_read`. This means if we have a nested expression like following,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "> ((1 2) 3)\n",
    "((1 2) 3)\n",
    "Pair(Pair(1, Pair(2, nil)), Pair(3, nil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we find the first `(`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "`(`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we'll execute the following in `scheme_read`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elif val == \"(\":\n",
    "    return read_tail(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It calls a recursive `read_tail`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = scheme_read(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it executes the line above, which calls `scheme_read` to read the expression after the first `(`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...which is used as the `first` element in the..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair(1, Pair(2, nil))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the second element,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pair(3, nil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...would give us the rest of the list.\n",
    "\n",
    "We'll extend this small program in our project to handle `'` and `.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
